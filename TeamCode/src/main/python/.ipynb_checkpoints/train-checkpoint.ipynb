{
 "cells": [
  {
   "cell_type": "code",
   "id": "3f88c3af-b329-4269-893b-07d0edf696b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.786110Z",
     "start_time": "2024-02-27T01:59:34.773614Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image \n",
    "import cv2 \n",
    "from random import shuffle\n",
    "import glob\n",
    "import tables\n",
    "import cv2\n",
    "from math import ceil\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "05066264-f88c-4cbe-b2c4-3161e0411c3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.802982Z",
     "start_time": "2024-02-27T01:59:34.791708Z"
    }
   },
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNum GPUs Available: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(\u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlist_physical_devices(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "ad014cdd-af50-4ddc-874a-004b4ca526e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.845832Z",
     "start_time": "2024-02-27T01:59:34.842491Z"
    }
   },
   "source": [
    "# fileslist = [f for f in os.listdir(\"./blue/left\") if f.endswith('.jpg')]\n",
    "# img = Image.open('./blue/left/'+fileslist[0])\n",
    "\n",
    "# c = 100\n",
    "# for i in fileslist:\n",
    "#     img = Image.open('./blue/left/'+i)\n",
    "#     image_arr = np.array(img) \n",
    "#     # image_arr = cv2.GaussianBlur(image_arr, (101, 101), 0)\n",
    "#     image_1 = image_arr[0:320,0:480] \n",
    "#     image_2 = image_arr[0:320,480:960]\n",
    "#     image_3 = image_arr[0:320,960:1440]\n",
    "#     image_1 = Image.fromarray(image_1)\n",
    "#     image_2 = Image.fromarray(image_2)\n",
    "#     image_3 = Image.fromarray(image_3)\n",
    "#     image_1.save(\"./blue/train/cone/\"+str(c)+'.jpg')\n",
    "#     image_3.save(\"./blue/train/none/\"+str(c+1)+'.jpg')\n",
    "#     image_2.save(\"./blue/train/none/\"+str(c+2)+'.jpg')\n",
    "#     c+=3\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d781b20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.869021Z",
     "start_time": "2024-02-27T01:59:34.865891Z"
    }
   },
   "source": [
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "hdf5_path = './blue/dataset.hdf5'  # address to where you want to save the hdf5 file\n",
    "train_path = './blue/train/*/*.jpg' # path of the directory where image data is stored.\n",
    "data_order = 'tf' # different library uses different data ordering `tf` is used for tensor flow."
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "0bb98b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.937097Z",
     "start_time": "2024-02-27T01:59:34.900004Z"
    }
   },
   "source": [
    "addrs = glob.glob(train_path)\n",
    "labels = [0 if 'none' in addr else 1 for addr in addrs]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m addrs \u001B[38;5;241m=\u001B[39m \u001B[43mglob\u001B[49m\u001B[38;5;241m.\u001B[39mglob(train_path)\n\u001B[1;32m      2\u001B[0m labels \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m addr \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m addr \u001B[38;5;129;01min\u001B[39;00m addrs]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'glob' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fb35270a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.939147Z",
     "start_time": "2024-02-27T01:59:34.938658Z"
    }
   },
   "source": [
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "440cdca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.940412Z",
     "start_time": "2024-02-27T01:59:34.940267Z"
    }
   },
   "source": [
    "train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "train_labels = labels[0:int(0.6*len(labels))]\n",
    "\n",
    "val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]\n",
    "print('train size:',len(train_addrs))\n",
    "print('val size:',len(val_addrs))\n",
    "print('test size:',len(test_addrs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b4a1941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:34.977841Z",
     "start_time": "2024-02-27T01:59:34.952763Z"
    }
   },
   "source": [
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved\n",
    "\n",
    "# check the order of data and chose proper data shape to save images\n",
    "if data_order == 'th':\n",
    "    data_shape = (0, 3, 256, 256)\n",
    "elif data_order == 'tf':\n",
    "    data_shape = (0, 256, 256, 3)\n",
    "\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = tables.open_file(hdf5_path, mode='w')\n",
    "try:\n",
    "    train_storage = hdf5_file.create_earray(hdf5_file.root, 'train_img', img_dtype, shape=data_shape)\n",
    "    val_storage = hdf5_file.create_earray(hdf5_file.root, 'val_img', img_dtype, shape=data_shape)\n",
    "    test_storage = hdf5_file.create_earray(hdf5_file.root, 'test_img', img_dtype, shape=data_shape)\n",
    "    \n",
    "    mean_storage = hdf5_file.create_earray(hdf5_file.root, 'train_mean', img_dtype, shape=data_shape)\n",
    "    \n",
    "    # create the label arrays and copy the labels data in them\n",
    "    hdf5_file.create_array(hdf5_file.root, 'train_labels', train_labels)\n",
    "    hdf5_file.create_array(hdf5_file.root, 'val_labels', val_labels)\n",
    "    hdf5_file.create_array(hdf5_file.root, 'test_labels', test_labels)\n",
    "    \n",
    "    # a numpy array to save the mean of the images\n",
    "    mean = np.zeros(data_shape[1:], np.float32)\n",
    "    \n",
    "    # loop over train addresses\n",
    "    for i in range(len(train_addrs)):\n",
    "        # print how many images are saved every 100 images\n",
    "        if i % 10 == 0 and i > 1:\n",
    "            print('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "    \n",
    "        # read an image and resize to (224, 224)\n",
    "        # cv2 load images as BGR, convert it to RGB\n",
    "        addr = train_addrs[i]\n",
    "        #print(addr)\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # add any image pre-processing here\n",
    "    \n",
    "        # if the data order is Theano, axis orders should change\n",
    "        if data_order == 'th':\n",
    "            img = np.rollaxis(img, 2)\n",
    "    \n",
    "        # save the image and calculate the mean so far\n",
    "        train_storage.append(img[None])\n",
    "        mean += img / float(len(train_labels))\n",
    "    \n",
    "    # loop over validation addresses\n",
    "    for i in range(len(val_addrs)):\n",
    "        # print how many images are saved every 1000 images\n",
    "        if i % 10 == 0 and i > 1:\n",
    "            print ('Validation data: {}/{}'.format(i, len(val_addrs)))\n",
    "    \n",
    "        # read an image and resize to (256, 256)\n",
    "        # cv2 load images as BGR, convert it to RGB\n",
    "        addr = val_addrs[i]\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # add any image pre-processing here\n",
    "    \n",
    "        # if the data order is Theano, axis orders should change\n",
    "        if data_order == 'th':\n",
    "            img = np.rollaxis(img, 2)\n",
    "    \n",
    "        # save the image\n",
    "        val_storage.append(img[None])\n",
    "    \n",
    "    # loop over test addresses\n",
    "    for i in range(len(test_addrs)):\n",
    "        # print how many images are saved every 1000 images\n",
    "        if i % 10 == 0 and i > 1:\n",
    "            print ('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "    \n",
    "        # read an image and resize to (224, 224)\n",
    "        # cv2 load images as BGR, convert it to RGB\n",
    "        addr = test_addrs[i]\n",
    "        #print(addr)\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # add any image pre-processing here\n",
    "    \n",
    "        # if the data order is Theano, axis orders should change\n",
    "        if data_order == 'th':\n",
    "            img = np.rollaxis(img, 2)\n",
    "    \n",
    "        # save the image\n",
    "        test_storage.append(img[None])\n",
    "    \n",
    "    # save the mean and close the hdf5 file\n",
    "    mean_storage.append(mean[None])\n",
    "    print('HDF5 Done')\n",
    "finally:\n",
    "    print('In Finally')\n",
    "    hdf5_file.close()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m data_order \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# 'th' for Theano, 'tf' for Tensorflow\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m img_dtype \u001B[38;5;241m=\u001B[39m \u001B[43mtables\u001B[49m\u001B[38;5;241m.\u001B[39mUInt8Atom()  \u001B[38;5;66;03m# dtype in which the images will be saved\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# check the order of data and chose proper data shape to save images\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data_order \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mth\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tables' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c1d7b5a2",
   "metadata": {},
   "source": [
    "hdf5_path = './blue/dataset.hdf5'  # Path where dataset.hdf5 file is stored\n",
    "subtract_mean = True\n",
    "batch_size = 50\n",
    "nb_class = 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ce5df59",
   "metadata": {},
   "source": [
    "hdf5_file = tables.open_file(hdf5_path, mode='r')\n",
    "# subtract the training mean\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file.root.train_mean[0]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "\n",
    "# Total number of samples\n",
    "train_data = np.array(hdf5_file.root.train_img)\n",
    "train_label = np.array(hdf5_file.root.train_labels)\n",
    "\n",
    "test_data = np.array(hdf5_file.root.test_img)\n",
    "test_label = np.array(hdf5_file.root.test_labels)\n",
    "\n",
    "val_data = np.array(hdf5_file.root.val_img)\n",
    "val_label = np.array(hdf5_file.root.val_labels)\n",
    "\n",
    "print('train data:',train_data.shape,' train_label',train_label.shape)\n",
    "print('test_data:',test_data.shape,' test_label:',test_label.shape)\n",
    "print('val_data:',val_data.shape,' val_label:',val_label.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "785ec253",
   "metadata": {},
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = len(np.unique(train_label))\n",
    "train_label = to_categorical(train_label, num_classes)\n",
    "test_label = to_categorical(test_label, num_classes)\n",
    "val_label = to_categorical(val_label, num_classes)\n",
    "\n",
    "# print shape of training set\n",
    "print('num_classes:', num_classes)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(train_label.shape, 'train samples')\n",
    "print(test_label.shape, 'test samples')\n",
    "print(val_label.shape, 'validation samples')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1d4983f-feee-4e35-9a3b-1cfd5efdcddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:35.034897Z",
     "start_time": "2024-02-27T01:59:35.020974Z"
    }
   },
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(256, 256, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='tanh'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='tanh'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "# model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "model.summary()\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mSequential()\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39madd(tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mConv2D(filters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m      3\u001B[0m                         input_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m3\u001B[39m)))\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39madd(tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mMaxPooling2D(pool_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "4b098f55",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='selu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "model.summary()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55070b0c-a4a8-4295-b417-07098c622620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:35.052081Z",
     "start_time": "2024-02-27T01:59:35.040815Z"
    }
   },
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmsprop\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m      2\u001B[0m                   metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "997789e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:35.092402Z",
     "start_time": "2024-02-27T01:59:35.075881Z"
    }
   },
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best_200.hdf5', verbose=1, \n",
    "                               save_best_only=True,monitor='val_accuracy', mode = \"max\")\n",
    "hist = model.fit(train_data, train_label, batch_size=None, epochs=200,\n",
    "          validation_data=(val_data, val_label),callbacks=[checkpointer], \n",
    "          verbose=1, shuffle=True)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcallbacks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCheckpoint   \n\u001B[1;32m      3\u001B[0m checkpointer \u001B[38;5;241m=\u001B[39m ModelCheckpoint(filepath\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel.weights.best_200.hdf5\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, \n\u001B[1;32m      4\u001B[0m                                save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m hist \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(train_data, train_label, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[1;32m      6\u001B[0m           validation_data\u001B[38;5;241m=\u001B[39m(val_data, val_label),callbacks\u001B[38;5;241m=\u001B[39m[checkpointer], \n\u001B[1;32m      7\u001B[0m           verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'keras'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "047b21f2-5426-4bfa-85e3-b6ee3c2a76c7",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(hist.history['accuracy'], label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.savefig(\"output_report.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9aa56a8f-b273-4b9f-aea8-a842c980552c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:35.106611Z",
     "start_time": "2024-02-27T01:59:35.095598Z"
    }
   },
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "score = model.evaluate(test_data, test_label, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mload_weights(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel.weights.best.hdf5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m score \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(test_data, test_label, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest accuracy:\u001B[39m\u001B[38;5;124m'\u001B[39m, score[\u001B[38;5;241m1\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "22d05428",
   "metadata": {},
   "source": [
    "tf.version.VERSION"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0386351f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:59:35.175150Z",
     "start_time": "2024-02-27T01:59:35.162344Z"
    }
   },
   "source": [
    "x = 3\n",
    "a = model.predict(np.expand_dims(test_data[x], axis=0))\n",
    "print(a[0])\n",
    "score = tf.nn.softmax(a[0])\n",
    "print(score)\n",
    "img = Image.fromarray(test_data[x])\n",
    "img.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m----> 2\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39mexpand_dims(test_data[x], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(a[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      4\u001B[0m score \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39msoftmax(a[\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "03b6df21-e3ca-49df-8ec7-792bc73778f2",
   "metadata": {},
   "source": [
    "x = 10\n",
    "a = model.predict(np.expand_dims(test_data[x], axis=0))\n",
    "print(a[0])\n",
    "score = tf.nn.softmax(a[0])\n",
    "print(score)\n",
    "img = Image.fromarray(test_data[x])\n",
    "img.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
